#!/bin/bash

# Reddit Scraper - Complete Demo Script
# This script demonstrates all features of the Reddit Scraper

echo "ğŸš€ Reddit Scraper - Complete Feature Demo"
echo "=========================================="

# Check if Python is available
if ! command -v python &> /dev/null; then
    echo "âŒ Python is not installed or not in PATH"
    exit 1
fi

# Check if we're in the right directory
if [ ! -f "run.py" ]; then
    echo "âŒ Please run this script from the reddit-scraper directory"
    exit 1
fi

echo "ğŸ“¦ Installing dependencies..."
pip install -r requirements.txt

echo ""
echo "ğŸ”§ Setting up configuration..."
python run.py create-config

echo ""
echo "âš ï¸  IMPORTANT: Please edit config/settings.yaml with your Reddit API credentials"
echo "   1. Go to https://www.reddit.com/prefs/apps"
echo "   2. Create a new app (script type)"
echo "   3. Copy client_id and client_secret to config/settings.yaml"
echo ""
read -p "Press Enter after configuring your Reddit API credentials..."

echo ""
echo "ğŸ” Testing Reddit API connection..."
python run.py test-connection

echo ""
echo "ğŸ¯ Running feature demonstrations..."

echo ""
echo "1ï¸âƒ£  Basic Scraping Demo"
python run.py scrape --subreddit python --posts 10

echo ""
echo "2ï¸âƒ£  HTML Report Demo (with dark theme and charts)"
python run.py scrape --subreddit programming --posts 15 --output html

echo ""
echo "3ï¸âƒ£  Parallel Processing Demo"
python run.py scrape --subreddit "python,datascience,programming" --posts 8 --parallel --max-workers 3

echo ""
echo "4ï¸âƒ£  Content Extraction Demo"
python run.py scrape --subreddit technology --posts 10 --extract-content

echo ""
echo "5ï¸âƒ£  Performance Monitoring Demo"
python run.py scrape --subreddit datascience --posts 12 --performance-monitor

echo ""
echo "6ï¸âƒ£  All Features Combined Demo"
python run.py scrape --subreddit "python,programming" --posts 10 --parallel --extract-content --include-users --performance-monitor --output "json,csv,html" --min-score 5

echo ""
echo "ğŸ§ª Running Tests..."
python run_tests.py --unit

echo ""
echo "ğŸ“Š Running Performance Benchmarks..."
python run_tests.py --benchmark

echo ""
echo "ğŸ‰ Demo Complete!"
echo "=================="

echo ""
echo "ğŸ“ Generated Files:"
echo "â€¢ output/html/ - Interactive HTML reports (open in browser)"
echo "â€¢ output/json/ - Structured JSON data"
echo "â€¢ output/csv/ - Spreadsheet-compatible data"
echo "â€¢ logs/ - Performance metrics and logs"
echo "â€¢ htmlcov/ - Test coverage reports"

echo ""
echo "ğŸŒŸ Key Features Demonstrated:"
echo "âœ… HTML reports with dark theme and interactive charts"
echo "âœ… Parallel processing for 5x faster scraping"
echo "âœ… Content extraction from external links"
echo "âœ… Performance monitoring and optimization"
echo "âœ… Comprehensive testing suite"
echo "âœ… Multiple export formats"

echo ""
echo "ğŸ”— Next Steps:"
echo "1. Open output/html/*.html files in your browser"
echo "2. Analyze data in output/csv/ with Excel/Google Sheets"
echo "3. Use output/json/ data for further processing"
echo "4. Review performance metrics in logs/"

echo ""
echo "ğŸ’¡ Pro Tips:"
echo "â€¢ Use --parallel for multiple subreddits"
echo "â€¢ Add --extract-content for rich data"
echo "â€¢ Enable --performance-monitor for optimization"
echo "â€¢ Try --output html for beautiful reports"

echo ""
echo "ğŸ“– For more information, see README.md"
echo "ğŸ› Report issues at: https://github.com/pixelbrow720/reddit-scraper"